llama-stack == 0.2.20
llama-stack-client == 0.2.20
fastapi >= 0.104.0
uvicorn >= 0.24.0
pydantic >= 2.0.0