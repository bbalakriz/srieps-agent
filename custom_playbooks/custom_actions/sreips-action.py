from robusta.api import *
import requests
import os
import re

# SREIPS Agent API endpoint - externalized
SREIPS_AGENT_URL = os.getenv("SREIPS_AGENT_URL", "http://sreips-agent.sreips-agent.svc.cluster.local:8000")

# Prompt mapping based on common Kubernetes failure reasons
PROMPT_MAPPINGS = {
    "CrashLoopBackOff": "what is the resolution for pod crashloop backoff issues in kubernetes?",
    "ImagePullBackOff": "what is the resolution for image pull backoff issues in kubernetes?",
    "ErrImagePull": "what is the resolution for image pull errors in kubernetes?",
    "CreateContainerConfigError": "what is the resolution for container configuration errors in kubernetes?",
    "InvalidImageName": "what is the resolution for invalid image name errors in kubernetes?",
    "CreateContainerError": "what is the resolution for container creation errors in kubernetes?",
    "RunContainerError": "what is the resolution for run container errors in kubernetes?",
    "OOMKilled": "what is the resolution for out of memory killed pods in kubernetes?",
    "Evicted": "what is the resolution for evicted pods in kubernetes?",
    "FailedScheduling": "what is the resolution for failed pod scheduling in kubernetes?",
    "NodeNotReady": "what is the resolution for node not ready issues in kubernetes?",
    "NetworkNotReady": "what is the resolution for network not ready issues in kubernetes?",
    "PersistentVolumeClaimNotBound": "what is the resolution for PVC not bound issues in kubernetes?",
    "VolumeAttachFailed": "what is the resolution for volume attachment failures in kubernetes?",
}

def extract_failure_reason(pod, pod_logs: str) -> str:
    """
    Extract the failure reason from pod status and logs
    Returns a string describing the failure
    
    Based on Robusta's PodEvent structure:
    - pod.status.containerStatuses (camelCase)
    - container_status.state.waiting.reason
    - container_status.state.terminated.reason
    
    Reference: https://github.com/robusta-dev/robusta/blob/master/src/robusta/integrations/kubernetes/autogenerated/events.py
    """
    try:
        # Check container statuses (Robusta uses camelCase: containerStatuses)
        if pod.status and hasattr(pod.status, 'containerStatuses') and pod.status.containerStatuses:
            for container_status in pod.status.containerStatuses:
                # Check waiting state first (more common for ongoing issues)
                if (container_status.state and 
                    container_status.state.waiting and 
                    container_status.state.waiting.reason):
                    reason = container_status.state.waiting.reason
                    if reason in PROMPT_MAPPINGS:
                        return reason
                
                # Check terminated state
                if (container_status.state and 
                    container_status.state.terminated and 
                    container_status.state.terminated.reason):
                    reason = container_status.state.terminated.reason
                    if reason in PROMPT_MAPPINGS:
                        return reason
        
        # Check pod conditions as fallback
        if pod.status and hasattr(pod.status, 'conditions') and pod.status.conditions:
            for condition in pod.status.conditions:
                if (hasattr(condition, 'status') and 
                    hasattr(condition, 'reason') and
                    condition.status == "False" and 
                    condition.reason and
                    condition.reason in PROMPT_MAPPINGS):
                    return condition.reason
                    
    except AttributeError as e:
        # Log the specific attribute error for debugging
        print(f"AttributeError while parsing pod status: {e}")
    except Exception as e:
        # Catch any other unexpected errors
        print(f"Unexpected error parsing pod status: {e}")
    
    # Parse logs for common error patterns as final fallback
    if pod_logs:
        log_lower = pod_logs.lower()
        if "out of memory" in log_lower or "oom" in log_lower:
            return "OOMKilled"
        elif "image pull" in log_lower or "imagepullbackoff" in log_lower:
            return "ImagePullBackOff"
        elif "crashloopbackoff" in log_lower or "crash loop" in log_lower:
            return "CrashLoopBackOff"
        elif "evicted" in log_lower:
            return "Evicted"
    
    # Default to CrashLoopBackOff if we can't determine
    return "CrashLoopBackOff"

def query_sreips_agent(query: str) -> dict:
    """
    Call the SREIPS Agent API with the given query
    Returns the combined results or error message
    """
    try:
        response = requests.post(
            f"{SREIPS_AGENT_URL}/query",
            json={"query": query},
            timeout=600
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.Timeout:
        return {"combined_results": "Error: Request to SREIPS Agent timed out"}
    except requests.exceptions.ConnectionError:
        return {"combined_results": f"Error: Could not connect to SREIPS Agent at {SREIPS_AGENT_URL}"}
    except Exception as e:
        return {"combined_results": f"Error querying SREIPS Agent: {str(e)}"}

@action
def lls_agent_action(event: PodEvent):
    # we have full access to the pod on which the alert fired
    pod = event.get_pod()
    pod_name = pod.metadata.name
    pod_namespace = pod.metadata.namespace
    pod_logs = pod.get_logs()
    
    # Extract failure reason from pod status and logs
    failure_reason = extract_failure_reason(pod, pod_logs)
    
    # Get the appropriate prompt
    prompt = PROMPT_MAPPINGS.get(failure_reason, PROMPT_MAPPINGS["CrashLoopBackOff"])
    
    # Query the SREIPS Agent
    results = query_sreips_agent(prompt)
    combined_results = results.get("combined_results", "No results returned from SREIPS Agent")
    
    # this is how you send data to slack or other destinations
    event.add_enrichment([
        MarkdownBlock(f"*Alert:* Pod `{pod_name}` in namespace `{pod_namespace}` is experiencing issues"),
        MarkdownBlock(f"*Detected Issue:* {failure_reason}"),
        MarkdownBlock(f"*AI-Powered Resolution:*\n\n{combined_results}"),
        FileBlock(f"{pod_name}.log", pod_logs)
    ])